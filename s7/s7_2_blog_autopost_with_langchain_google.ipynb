{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv(dotenv_path='../.env')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yuriy/Github/Vistrem/learning/ActiveLoopLangchain/venv/lib/python3.11/site-packages/deeplake/util/check_latest_version.py:32: UserWarning: A newer version of deeplake (3.8.2) is available. It's recommended that you update to the latest version using `pip install -U deeplake`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.prompts.chat import ChatPromptTemplate, HumanMessagePromptTemplate\n",
    "\n",
    "from langchain.tools import Tool\n",
    "from langchain.utilities import GoogleSearchAPIWrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "title = \"OpenAI CEO: AI regulation ‘is essential’\"\n",
    "\n",
    "text_all = \"\"\"Altman highlighted the potential benefits of AI technologies like ChatGPT and Dall-E 2 to help address significant challenges such as climate change and cancer, but he also stressed the need to mitigate the risks associated with increasingly powerful AI models.\n",
    "Altman proposed that governments consider implementing licensing and testing requirements for AI models that surpass a certain threshold of capabilities.\n",
    "He highlighted OpenAI’s commitment to safety and extensive testing before releasing any new systems, emphasising the company’s belief that ensuring the safety of AI is crucial.\n",
    "Senators Josh Hawley and Richard Blumenthal expressed their recognition of the transformative nature of AI and the need to understand its implications for elections, jobs, and security.\n",
    "Blumenthal played an audio introduction using an AI voice cloning software trained on his speeches, demonstrating the potential of the technology.\n",
    "Blumenthal raised concerns about various risks associated with AI, including deepfakes, weaponised disinformation, discrimination, harassment, and impersonation fraud.\n",
    "He also emphasised the potential displacement of workers in the face of a new industrial revolution driven by AI.\"\"\"\n",
    "\n",
    "text_to_change = \"\"\"Senators Josh Hawley and Richard Blumenthal expressed their recognition of the transformative nature of AI and the need to understand its implications for elections, jobs, and security.\n",
    "Blumenthal played an audio introduction using an AI voice cloning software trained on his speeches, demonstrating the potential of the technology.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"\"\" You are an exceptional copywriter and content creator.\n",
    "\n",
    "You're reading an article with the following title:\n",
    "----------------\n",
    "{title}\n",
    "----------------\n",
    "\n",
    "You've just read the following piece of text from that article.\n",
    "----------------\n",
    "{text_all}\n",
    "----------------\n",
    "\n",
    "Inside that text, there's the following TEXT TO CONSIDER that you want to enrich with new details.\n",
    "----------------\n",
    "{text_to_change}\n",
    "----------------\n",
    "\n",
    "What are some simple and high-level Google queries that you'd do to search for more info to add to that paragraph?\n",
    "Write 3 queries as a bullet point list, prepending each line with -.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "human_message_prompt = HumanMessagePromptTemplate(\n",
    "    prompt=PromptTemplate(\n",
    "        template=template,\n",
    "        input_variables=[\"text_to_change\", \"text_all\", \"title\"],\n",
    "    )\n",
    ")\n",
    "chat_prompt_template = ChatPromptTemplate.from_messages([human_message_prompt])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['- \"AI implications for elections\"', '- \"AI implications for jobs\"', '- \"AI implications for security\"']\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Tool.__init__() missing 1 required positional argument: 'func'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/Users/yuriy/Github/Vistrem/learning/ActiveLoopLangchain/s7/s7_2_blog_autopost_with_langchain_google.ipynb Cell 6\u001b[0m line \u001b[0;36m1\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/yuriy/Github/Vistrem/learning/ActiveLoopLangchain/s7/s7_2_blog_autopost_with_langchain_google.ipynb#W5sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mtop_n_results\u001b[39m(query):\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/yuriy/Github/Vistrem/learning/ActiveLoopLangchain/s7/s7_2_blog_autopost_with_langchain_google.ipynb#W5sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m search\u001b[39m.\u001b[39mresults(query, TOP_N_RESULT)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/yuriy/Github/Vistrem/learning/ActiveLoopLangchain/s7/s7_2_blog_autopost_with_langchain_google.ipynb#W5sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m tool \u001b[39m=\u001b[39m Tool(\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/yuriy/Github/Vistrem/learning/ActiveLoopLangchain/s7/s7_2_blog_autopost_with_langchain_google.ipynb#W5sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m     name \u001b[39m=\u001b[39;49m \u001b[39m\"\u001b[39;49m\u001b[39mGoogle Search\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/yuriy/Github/Vistrem/learning/ActiveLoopLangchain/s7/s7_2_blog_autopost_with_langchain_google.ipynb#W5sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m     description \u001b[39m=\u001b[39;49m \u001b[39m\"\u001b[39;49m\u001b[39mSearches Google for the top 5 results for a given query.\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/yuriy/Github/Vistrem/learning/ActiveLoopLangchain/s7/s7_2_blog_autopost_with_langchain_google.ipynb#W5sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m )\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/yuriy/Github/Vistrem/learning/ActiveLoopLangchain/s7/s7_2_blog_autopost_with_langchain_google.ipynb#W5sZmlsZQ%3D%3D?line=23'>24</a>\u001b[0m all_results \u001b[39m=\u001b[39m []\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/yuriy/Github/Vistrem/learning/ActiveLoopLangchain/s7/s7_2_blog_autopost_with_langchain_google.ipynb#W5sZmlsZQ%3D%3D?line=25'>26</a>\u001b[0m \u001b[39mfor\u001b[39;00m query \u001b[39min\u001b[39;00m queries:\n",
      "\u001b[0;31mTypeError\u001b[0m: Tool.__init__() missing 1 required positional argument: 'func'"
     ]
    }
   ],
   "source": [
    "chat = ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature=0.9)\n",
    "chain = LLMChain(llm=chat, prompt=chat_prompt_template)\n",
    "\n",
    "response = chain.run({\n",
    "    \"text_to_change\": text_to_change,\n",
    "    \"text_all\": text_all,\n",
    "    \"title\": title,\n",
    "})\n",
    "\n",
    "queries = [line for line in response.split(\"\\n\")]\n",
    "print(queries)\n",
    "\n",
    "search = GoogleSearchAPIWrapper()\n",
    "TOP_N_RESULT = 5\n",
    "\n",
    "def top_n_results(query):\n",
    "    return search.results(query, TOP_N_RESULT)\n",
    "\n",
    "tool = Tool(\n",
    "    name = \"Google Search\",\n",
    "    description = \"Searches Google for the top 5 results for a given query.\",\n",
    "    func = top_n_results,\n",
    ")\n",
    "\n",
    "all_results = []\n",
    "\n",
    "for query in queries:\n",
    "    results = tool.run(query)\n",
    "    all_results.append(results[0])\n",
    "\n",
    "print(all_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of pages with content: 2\n"
     ]
    }
   ],
   "source": [
    "import newspaper\n",
    "pages_content = []\n",
    "\n",
    "for result in all_results:\n",
    "    try:\n",
    "        article = newspaper.Article(result[\"link\"])\n",
    "        article.download()\n",
    "        article.parse()\n",
    "        \n",
    "        if len(article.text) > 0:\n",
    "            pages_content.append({\"url\": result[\"link\"], \"text\": article.text})\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        pass\n",
    "\n",
    "print(\"Number of pages with content:\", len(pages_content))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of docs: 37\n"
     ]
    }
   ],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.docstore.document import Document\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=100)\n",
    "\n",
    "docs = []\n",
    "\n",
    "for d in pages_content:\n",
    "    chunks = text_splitter.split_text(d[\"text\"])\n",
    "\n",
    "    for chunk in chunks:\n",
    "        new_doc = Document(page_content=chunk, metadata={\"source\": d[\"url\"]})\n",
    "        docs.append(new_doc)\n",
    "\n",
    "print(\"Number of docs:\", len(docs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "\n",
    "embeddings = OpenAIEmbeddings()\n",
    "\n",
    "docs_embeddings = embeddings.embed_documents([doc.page_content for doc in docs])\n",
    "query_embedding = embeddings.embed_query(text_to_change)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "def get_top_k_indices(list_of_doc_vectors, query_vector, top_k):\n",
    "    # convert the lists of vectors to numpy arrays\n",
    "    list_of_doc_vectors = np.array(list_of_doc_vectors)\n",
    "    query_vector = np.array(query_vector)\n",
    "\n",
    "    # compute cosine similarities\n",
    "    similarities = cosine_similarity(query_vector.reshape(1, -1), list_of_doc_vectors).flatten()\n",
    "\n",
    "    # sort the vectors based on cosine similarity\n",
    "    sorted_indices = np.argsort(similarities)[::-1]\n",
    "\n",
    "    # retrieve the top K indices from the sorted list\n",
    "    top_k_indices = sorted_indices[:top_k]\n",
    "\n",
    "    return top_k_indices\n",
    "\n",
    "top_k = 3\n",
    "best_indexes = get_top_k_indices(docs_embeddings, query_embedding, top_k)\n",
    "best_k_documents = [doc for i, doc in enumerate(docs) if i in best_indexes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text to Change:  Senators Josh Hawley and Richard Blumenthal expressed their recognition of the transformative nature of AI and the need to understand its implications for elections, jobs, and security.\n",
      "Blumenthal played an audio introduction using an AI voice cloning software trained on his speeches, demonstrating the potential of the technology.\n",
      "Expanded Variation: Senators Josh Hawley and Richard Blumenthal expressed their recognition of the transformative nature of AI and the need to understand its implications for elections, jobs, and security. They highlighted the concerning issue of disinformation risks in the upcoming 2024 elections, which have been amplified by advancements in AI technology. Blumenthal even showcased the potential of AI by playing an audio introduction created using an AI voice cloning software trained on his speeches. This demonstration raised further concerns about the misuse of AI-generated content, as malicious actors could potentially deploy generative AI to suppress votes or undermine election defenses. In light of these risks, both senators emphasized the urgent need for Congress and state legislatures to swiftly regulate AI to protect the integrity of elections.\n"
     ]
    }
   ],
   "source": [
    "template = \"\"\"You are an exceptional copywriter and content creator.\n",
    "\n",
    "You're reading an article with the following title:\n",
    "----------------\n",
    "{title}\n",
    "----------------\n",
    "\n",
    "You've just read the following piece of text from that article.\n",
    "----------------\n",
    "{text_all}\n",
    "----------------\n",
    "\n",
    "Inside that text, there's the following TEXT TO CONSIDER that you want to enrich with new details.\n",
    "----------------\n",
    "{text_to_change}\n",
    "----------------\n",
    "\n",
    "Searching around the web, you've found this ADDITIONAL INFORMATION from distinct articles.\n",
    "----------------\n",
    "{doc_1}\n",
    "----------------\n",
    "{doc_2}\n",
    "----------------\n",
    "{doc_3}\n",
    "----------------\n",
    "\n",
    "Modify the previous TEXT TO CONSIDER by enriching it with information from the previous ADDITIONAL INFORMATION.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "human_message_prompt = HumanMessagePromptTemplate(\n",
    "    prompt=PromptTemplate(\n",
    "        template=template,\n",
    "        input_variables=[\"text_to_change\", \"text_all\", \"title\", \"doc_1\", \"doc_2\", \"doc_3\"],\n",
    "    )\n",
    ")\n",
    "chat_prompt_template = ChatPromptTemplate.from_messages([human_message_prompt])\n",
    "\n",
    "chat = ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature=0.9)\n",
    "chain = LLMChain(llm=chat, prompt=chat_prompt_template)\n",
    "\n",
    "response = chain.run({\n",
    "    \"text_to_change\": text_to_change,\n",
    "    \"text_all\": text_all,\n",
    "    \"title\": title,\n",
    "    \"doc_1\": best_k_documents[0].page_content,\n",
    "    \"doc_2\": best_k_documents[1].page_content,\n",
    "    \"doc_3\": best_k_documents[2].page_content\n",
    "})\n",
    "\n",
    "print(\"Text to Change: \", text_to_change)\n",
    "print(\"Expanded Variation:\", response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
